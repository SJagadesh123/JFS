Making Microservices Resilient / Resilience in Microservices
===========================================================

Resilient = able to withstand or recover quickly from difficult conditions./ something capable of withstanding the tough times and bouncing back to a normal life. 

microservices are resilient in nature - so that they can withstand tough times like network problem or any performance issues - so these kind of challenges our microservices may face on day-to-day basis 

--------- Need of Resiliency inside Microservices -------------

Challenge # 7

1) How do we avoid cascading failures inside our microservices network?
    we all know that - inside a microservice network when my client application or my UI application is sending a request to the microservice network - many microservices will work together and they will send a combined response to the client application. In such scenario -how we are going to handle a scenario where one of the service is failing  or responding very slowly - how do we make sure that it is not having an effect on the other microservices
 accounts ---> loans & cards --- total response back to client
	--> loans or cards microservice fails - other microservices keep waiting
 we need to make sure that the entire chain of microservices does not fail if one of the  participating microservice is failing or is responding slowly

2) How do we handle failures gracefully with fallbacks?
    if any of the microservice (accounts) is not working - atleast we should be able to retun back cards or loans data information to client instead of sending an exception saying that we are not able to send any kind of information
   return a default value, or a value from cache or call another service

3) How to make our services self healing capable?
  If one of the participating microservice inside a microservice network is responding very slowly due to some performace issue or due to some network issues - how we are going to make our services self healing capable. how to configure some timeouts , retries or give time for a failed microservice to recover itself 

Solution:

-> inside microservices there are many patterns to build resilient applications. before in the java ecosystem we used to have a library called Hystrix (developed by Netflix team itself). Hystrix entered maintenance mode in 2018, now we use a new library - Resilience4J ; it supports many resilient related patterns which we can use based on business requirements

110, 111

Resilience4J --> is a lightweight fault tolerence library designed for functional programming. It offers the following patterns for increasing fault tolerence due to network problems or failure of any of the multiple services:
 --> Circuit Breaker -- used to stop making requests when a service invoked is failing
 --> Fallback -- alternative paths to failing requests
 --> Retry -- used to make retries when a service has temporarily failed
 --> Rate Limit -- lmits the number of calls that a services receives in a time
 --> Bulkhead -- limits the number of outgoing concurrent requests to a service to avoid overloading

reference: https://resilience4j.readme.io/   ---- Core Modules --- View More

	   https://resilience4j.readme.io/docs/getting-started


--------- Typical usecase or scenario for the need of Resiliency inside Microservices -------------
112

resource usage (memory, threads) is more in accounts microservice as it is waiting for the response from cards microservice and same happens in Edge server

-------- Circuit Breaker Pattern -------------
113
short circuit

circuit breaker pattern will stop all the future requests coming to the cards microservice and will send the immediate failed response to the accounts microservice and from there to gateway

--------- Three states of Circuit Breaker Pattern -------------

how circuit breaker pattern is going to control the traffic coming towards a particular microservice. by default circuit breaker is not going to monitor all the microservices - we need to configure the circuit breaker pattern wherever we need 

whenever we activate the circuit breaker pattern to any microservice - it is going to control the flow towards the microservice by using 3 different states
 (a) closed state
 (b) open state
 (c) half_open state

114


--------- Implement Circuit Breaker Pattern in Gateway & Implement Circuit Breaker Pattern with Feign Client -------------

task : implement circuit breaker pattern in Gateway server and  inside accounts microservice

-- inside gatewayserver project

dependency: Resilience4j  spring-cloud-starter-circuitbreaker-reactor-resilience4j
Spring Cloud Circuit breaker with Resilience4j as the underlying implementation

-- inside bootstrap class
@Bean
public RouteLocator zettaBankRouteConfig(RouteLocatorBuilder routeLocatorBuilder) {
 return routeLocatorBuilder.routes()
 	.route(p -> p
   		    .path("/zettabank/accounts/**")
		    .filters( f -> f.rewritePath("/zettabank/accounts/(?<segment>.*)","/${segment}")
				.addResponseHeader("X-Response-Time", LocalDateTime.now().toString())
				.circuitBreaker(config -> config.setName("accountsCircuitBreaker")))

		   .uri("lb://ACCOUNTS"))


-- in application.yml of gatewayserver

resilience4j.circuitbreaker:
  configs:
    default:
      slidingWindowSize: 10
      permittedNumberOfCallsInHalfOpenState: 2
      failureRateThreshold: 50
      waitDurationInOpenState: 10000


slidingWindowSize: 10  --- using this property we are communicating to the circuit breaker pattern on how many requests it has to initially monitor before it tries to change the status from closed to open state ; or in other words with this property we are telling to circuit breaker pattern please atleast monitor 10 requests coming towards our accounts microservice - after monitoring 10 requests take the decision whether to continue with the closed state or move to the open status

permittedNumberOfCallsInHalfOpenState: 2 --- once the circuit breaker pattern moved into open state - it will never be in open status for ever - periodically it is going to move to the half-open state and it is going to allow certain amount of traffic to the accounts microservice and since circuit breaker pattern cannot decide how many requests it has to pass - we need to provide such information to circuit breaker pattern using this property;  here we mentioned the value 2 - this means I want my circuit breaker pattern to allow 2 requests in the half-open status - based on how these 2 requests are processed - it can decide whether to go back to the open state or move to the close state 
 
failureRateThreshold: 50 ---- atleast 50% of my requests are failed then my circuit breaker pattern can move to the open state from the closed state 

waitDurationInOpenState: 10000 (10000ms) --- our circuit breaker pattern is going to wait for 10s whenever it will try to move to half-open state and allow the partial traffic.


resilience4j.circuitbreaker:
  configs:
    default:  ----> settings are applicable for all kind of circuit breakers that we are  going to create inside our microservice
            incase if we want to go with different different properties for different different circut breakers , then we need to use the circuit breaker name as we defined above as "accountsCircuitBreaker"


resilience4j.circuitbreaker:
  configs:
    accountsCircuitBreaker:


Run configserver, eureka server, accounts (only), gateway

http//localhost:8070/

--actuator of gateway server
http//localhost:8072/actuator    -- check for circuitbreakers
http//localhost:8072/actuator/circuitbreakers   --- empty now

test accounts microservice with gateway server all the circuit breaker related informations gets populated inside actuator/circuitbreaker

POSTMAN  --- GET http://localhost:8072/zettabank/accounts/api/contact-info

http//localhost:8072/actuator/circuitbreakers    --- content

--> to understand the events that are happening behind the scenes under the circuitbreaker

http//localhost:8072/actuator

http//localhost:8072/actuator/circuitbreakerevents?name=accountsCircuitBreaker  -- only one event
http://localhost:8072/actuator/circuitbreakerevents/accountsCircuitBreaker

POSTMAN  --- GET http://localhost:8072/zettabank/accounts/api/contact-info
POSTMAN  --- GET http://localhost:8072/zettabank/accounts/api/contact-info

http//localhost:8072/actuator/circuitbreakerevents?name=accountsCircuitBreaker   -- 3 events
from this we can understand that the circuit breaker is monitoring our microservice continuously

http//localhost:8072/actuator/circuitbreakers      bufferedCalls: 3, state: CLOSED

----> to check the real performance or demo of circut breaker pattern ---
inside AccountsController  (to mimic the slow response -- set a breakpoint on the following method)

@GetMapping
public ResponseEntity<AccountContactInfoDto> getContactInfo(){
  return ResponseEntity
		.status(HttpStatus.OK)
		.body(accountsContactInfo);
}

POSTMAN  --- GET http://localhost:8072/zettabank/accounts/api/contact-info
  ---> breakpoint stopped the execution

http//localhost:8072/actuator/circuitbreakerevents?name=accountsCircuitBreaker    type:ERROR

http//localhost:8072/actuator/circuitbreakers		state still in CLOSED state - 50% of the calls never failed

POSTMAN  --- GET http://localhost:8072/zettabank/accounts/api/contact-info  -- 4 times - check the error response


http//localhost:8072/actuator/circuitbreakerevents?name=accountsCircuitBreaker    type:ERROR, FAILURE_RATE_EXCEEDED, STATE_TRANSITION, NOT_PERMITTED

http//localhost:8072/actuator/circuitbreakers		


POSTMAN  --- GET http://localhost:8072/zettabank/accounts/api/contact-info 

now in HALF_OPEN state and after 2 requests it will be back to OPEN_STATE

release the breakpoint
---------------------------------------------------->

we have implemented circuit breaker pattern inside Gateway server - but does not have any fall back mechanism - since we dont have any fallback mechanism inside the response we are throwing some runtime exception details like service unavailable or gateway timeout exception etc. 

In real business applications throwing runtime exceptions to the client application or UI application is not a valid approach - we need to have some fallback mechanism and inside this fallback mechanism we can write some logic where we can send some message to the client applications which is going to make sense for them. 

--- To create a fallback mechanism for circuit breaker pattern 

inside gatewary server application - create a new controller class

package com.zettamine.gatewayserver.controller;

@RestController
public class FallbackController {
    @RequestMapping("/contactSupport")
    public Mono<String> contactSupport() {
        return Mono.just("An error occurred. Please try after some time or contact support team!!!");
    }
}


inside bootstrap class
@Bean
public RouteLocator zettaBankRouteConfig(RouteLocatorBuilder routeLocatorBuilder) 
{
 return routeLocatorBuilder.routes()
    .route(p -> p
	 	 .path("/zettabank/accounts/**")
		 .filters( f -> f.rewritePath("/zettabank/accounts/(?<segment>.*)","/${segment}")
		.addResponseHeader("X-Response-Time", LocalDateTime.now().toString())
		.circuitBreaker(config -> config.setName("accountsCircuitBreaker")
					.setFallbackUri("forward:/contactSupport")))
	.uri("lb://ACCOUNTS"))


POSTMAN GET  http://localhost:8072/zettabank/accounts/api/contact-info    <--- happy response

http://localhost:8072/actuator/circuitBreakers		state: CLOSED

http//localhost:8072/actuator/circuitbreakerevents?name=accountsCircuitBreaker

work with breakpoint in accounts microservice for mimicing slow response

POSTMAN GET  http://localhost:8072/zettabank/accounts/api/contact-info

release the breakpoint



--------- Implementing Circuit Breaker pattern with Feign Client  -------------

implementing circuit breaker pattern inside accounts microservice

inside accounts microservice - there is a REST API with name "/fetchCustomerDetails" - as part of this REST API our accounts microservice is going to invoke cards microservice and loans microservice - what if one of the dependent microservice like loans or cards microservice is responding very slowly or if they are completely down or there are some network issues. In such scenarios it is going to have some ripple effect of our accounts microservice and from account microservice to gateway server. 

we can implement circuit breaker pattern inside accounts microservice

spring.io > spring cloud > spring cloud openfeign > Learn > documentation > Feign SpringCloud Circuit Breaker support

-- in accounts microservice--

dependency - Resiliece4j (spring-cloud-starter-circuitbreaker-resilience4j -as we have not developed accounts microservice based on spring reactor)

-- application.yml of accounts microservice

spring:
  cloud:
    openfeign:
      circuitbreaker:
        enabled: true	--> to activate circuit breaker for all the openfeign clients inside the accounts microservice

resilience4j.circuitbreaker:
  configs:
    default:
      slidingWindowSize: 10
      permittedNumberOfCallsInHalfOpenState: 2
      failureRateThreshold: 50
      waitDurationInOpenState: 10000


spring.io > spring cloud > spring cloud openfeign > Learn > documentation > Feign SpringCloud Circuit Breaker Fallbacks

what should happen when loans/ cards microservice is down?

package com.zettamine.accounts.service.client;
@Component
public class LoansFallback implements LoansFeignClient{

    @Override
    public ResponseEntity<LoansDto> fetchLoanDetails(String correlationId, String mobileNumber) {
        return null; //to overcome from firing exception; atleast client gets accounts & cards details
    }
}


@Component
public class CardsFallback implements CardsFeignClient{

    @Override
    public ResponseEntity<CardsDto> fetchCardDetails(String correlationId, String mobileNumber) {
        return null;  
    }
}


@FeignClient(name="loans",fallback = LoansFallback.class)
public interface LoansFeignClient {


@FeignClient(name="cards", fallback = CardsFallback.class)
public interface CardsFeignClient {

--- CustomerServiceImpl class

ResponseEntity<LoansDto> loansDtoResponseEntity = loansFeignClient.fetchLoanDetails(correlationId, mobileNumber);
        if(loansDtoResponseEntity != null) {
            customerDetailsDto.setLoansDto(loansDtoResponseEntity.getBody());
        }

ResponseEntity<CardsDto> cardsDtoResponseEntity = cardsFeignClient.fetchCardDetails(correlationId, mobileNumber);
        if(cardsDtoResponseEntity != null) {
            customerDetailsDto.setCardsDto(cardsDtoResponseEntity.getBody());
        }

--- testing----

start all applications - confgiserver, eureka, accounts, loans, cards, gateway

accounts microservice actuator
http://localhost:8080/actuator
http://localhost:8080/actuator/circuitbreakers     --- no data

POSTMAN POST -- create data accounts, cards, loans
POSTMAN GET --- /fetchCustomerDetails

http://localhost:8080/actuator/circuitbreakers

http://localhost:8080/actuator/circuitbreakerEvents


stop loans microservice

POSTMAN GET --- fetchCustomerDetails  loansDto: null because of fallback mechanism
		try multiple times

http://localhost:8080/actuator/circuitbreakers    -- loans state: OPEN

http://localhost:8080/actuator/circuitbreakerEvents

stop cards microservices

POSTMAN GET --- fetchCustomerDetails  loansDto & cards: null because of fallback mechanism
		try multiple times

http://localhost:8080/actuator/circuitbreakers 
http://localhost:8080/actuator/circuitbreakerEvents

start loans & cards microservice
