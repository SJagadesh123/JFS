----------- Managing Logs with Grafana, Loki & Promtail --------------

we should not force the developers to implement all the observability and monitoring logic, instead we should leverage the tools or best practices that will help us to implement the observability and monitoring with less efforts from the developer.

for the same we use the tools or the plugins available inside grafana
Graphana is a company which is building lot of tools and plugins to implement observability and monitoring inside any kind of applications - not only about microservices , even for other type of applications like web applications, IoT applications 

Grafana provides opensource tools for various scenarios

grafana.com

Grafana Loki  - Log Aggreggating System (folder)
Promtail - collects logs from containers and forwards them to Loki
Prometheus - integrate it with grafana to build dashboards for metrics, alerts very easily
Grafana Tempo - for tracing

132
133

-- how to make log aggreggation without making changes in microservices?

https://grafana.com/docs/loki/latest/get-started/

flog - is an application provided by the Grafana team
flog generates and emits logs continuously   flog + logs  --> is a container
Promtail is the log agent working in the same microservice network - which reads the new logs generated by the flog , collects the new logs, 

MinIO is a storage system which stores the logs

134


::Practicals::

-- implementing Grfana, Loki and Promtail ----

-- application.yml of gatewayserver

spring.cloud.gateway.
 httpclient:
  response-timeout: 10s  (2s to 10s)


https://grafana.com/docs/loki/latest/get-started/   -- Prerequisites
						    -- Download loki-config

https://raw.githubusercontent.com/grafana/loki/main/examples/getting-started/docker-compose.yaml

read component of loki
command: -- will gets executed when we convert the docker image as a container   -target=read --- so that it becomes a read component of loki

volumes: using volumes we can map/ mount a file present inside the localhost system to the docker container
./loki-config.yaml -- in local system (download)
/etc/loki/config.yml -- copy to docker container

&loki-dns  -- defining a variable (anchor variable) with the name of loki-dns and it stores loki.aliases.loki

<<:  --- indicates merge operation inside YAML
* -- also a special symbol inside YAML used to refer anchor variables which are defined 

ro -- read only volume

mkdir -p  /data/loki-data  --- create a directiry inside local system

https://raw.githubusercontent.com/grafana/loki/main/examples/getting-started/loki-config.yaml
https://raw.githubusercontent.com/grafana/loki/main/examples/getting-started/promtail-local-config.yaml

docker-compose/observability/loki/loki-config.yaml
docker-compose/observability/promtail/promtail-local-config.yaml


from docker-compose.yml of perevious module

remove - redis container
gatewayserver: remove redis dependency, remove redis related environment variables
      : copy required things from the official docker-config.xml  - read: change volume: - ../observability/loki/loki-config.yaml

networks: zettabank

write: change volume:

promtail: config

grafana:
  neyworks: extends:


------------common-config.yml -------
services:
  network-deploy-service:
    networks:
      - zettabank

  microservice-base-config:
    extends:
      service: network-deploy-service
    deploy:
      resources:
        limits:
          memory: 700m

  microservice-configserver-config:
    extends:
      service: microservice-base-config
    depends_on:
      config-server:
        condition: service_healthy
    environment:
      SPRING_PROFILES_ACTIVE: default
      SPRING_CONFIG_IMPORT: configserver:http://config-server:8071/

  microservice-eureka-config:
    extends:
      service: microservice-configserver-config
    depends_on:
      eurekaserver:
        condition: service_healthy
    environment:
      EUREKA_CLIENT_SERVICEURL_DEFAULTZONE: http://eurekaserver:8070/eureka/


---docker-compose.yml -----
services:
  read:
    image: grafana/loki:2.9.2
    command: "-config.file=/etc/loki/config.yaml -target=read"
    ports:
      - 3101:3100
      - 7946
      - 9095
    volumes:
      - ../observability/loki/loki-config.yaml:/etc/loki/config.yaml
    depends_on:
      - minio
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks: &loki-dns
      zettabank:
        aliases:
          - loki

  write:
    image: grafana/loki:2.9.2
    command: "-config.file=/etc/loki/config.yaml -target=write"
    ports:
      - 3102:3100
      - 7946
      - 9095
    volumes:
      - ../observability/loki/loki-config.yaml:/etc/loki/config.yaml
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      - minio
    networks:
      <<: *loki-dns

  promtail:
    image: grafana/promtail:2.9.2
    volumes:
      - ../observability/promtail/promtail-local-config.yaml:/etc/promtail/config.yaml:ro
      - /var/run/docker.sock:/var/run/docker.sock
    command: -config.file=/etc/promtail/config.yaml
    depends_on:
      - gateway
    extends:
      file: common-config.yml
      service: network-deploy-service

  minio:
    image: minio/minio
    entrypoint:
      - sh
      - -euc
      - |
        mkdir -p /data/loki-data && \
        mkdir -p /data/loki-ruler && \
        minio server /data
    environment:
      - MINIO_ROOT_USER=loki
      - MINIO_ROOT_PASSWORD=supersecret
      - MINIO_PROMETHEUS_AUTH_TYPE=public
      - MINIO_UPDATE=off
    ports:
      - 9000
    volumes:
      - ./.data/minio:/data
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 15s
      timeout: 20s
      retries: 5
    extends:
      file: common-config.yml
      service: network-deploy-service
 
  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
    depends_on:
      - gateway
    entrypoint:
      - sh
      - -euc
      - |
        mkdir -p /etc/grafana/provisioning/datasources
        cat <<EOF > /etc/grafana/provisioning/datasources/ds.yaml
        apiVersion: 1
        datasources:
          - name: Loki
            type: loki
            access: proxy
            url: http://gateway:3100
            jsonData:
              httpHeaderName1: "X-Scope-OrgID"
            secureJsonData:
              httpHeaderValue1: "tenant1"
        EOF
        /run.sh
    ports:
      - "3000:3000"
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    extends:
      file: common-config.yml
      service: network-deploy-service

  gateway:
    image: nginx:latest
    depends_on:
      - read
      - write
    entrypoint:
      - sh
      - -euc
      - |
        cat <<EOF > /etc/nginx/nginx.conf
        user  nginx;
        worker_processes  5;  ## Default: 1

        events {
          worker_connections   1000;
        }

        http {
          resolver 127.0.0.11;

          server {
            listen             3100;

            location = / {
              return 200 'OK';
              auth_basic off;
            }

            location = /api/prom/push {
              proxy_pass       http://write:3100\$$request_uri;
            }

            location = /api/prom/tail {
              proxy_pass       http://read:3100\$$request_uri;
              proxy_set_header Upgrade \$$http_upgrade;
              proxy_set_header Connection "upgrade";
            }

            location ~ /api/prom/.* {
              proxy_pass       http://read:3100\$$request_uri;
            }

            location = /loki/api/v1/push {
              proxy_pass       http://write:3100\$$request_uri;
            }

            location = /loki/api/v1/tail {
              proxy_pass       http://read:3100\$$request_uri;
              proxy_set_header Upgrade \$$http_upgrade;
              proxy_set_header Connection "upgrade";
            }

            location ~ /loki/api/.* {
              proxy_pass       http://read:3100\$$request_uri;
            }
          }
        }
        EOF
        /docker-entrypoint.sh nginx -g "daemon off;"
    ports:
      - "3100:3100"
    healthcheck:
      test: [ "CMD", "service", "nginx", "status" ]
      interval: 10s
      timeout: 5s
      retries: 5
    extends:
      file: common-config.yml
      service: network-deploy-service

      
  config-server:
    image: "150478/configserver:v6"
    container_name: configserver-ms
    ports:
      - "8071:8071"
    healthcheck:
      test: "curl --fail --silent localhost:8071/actuator/health | grep UP || exit 1"
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 10s
    extends:
      file: common-config.yml
      service: microservice-base-config

  eurekaserver:
    image: "150478/eurekaserver:v6"
    container_name: eurekaserver-ms
    ports:
      - "8070:8070"
    healthcheck:
      test: "curl --fail --silent localhost:8070/actuator/health | grep UP || exit 1"
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 10s
    extends:
      file: common-config.yml
      service: microservice-configserver-config
    environment:
      SPRING_APPLICATION_NAME: "eurekaserver"

  accounts:
    image: "150478/accounts:v6"
    container_name: accounts-ms
    ports:
      - "8080:8080"
    healthcheck:
      test: "curl --fail --silent localhost:8080/actuator/health | grep UP || exit 1"
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 10s
    environment:
      SPRING_APPLICATION_NAME: "accounts"
    extends:
      file: common-config.yml
      service: microservice-eureka-config

  loans:
    image: "150478/loans:v6"
    container_name: loans-ms
    ports:
      - "8090:8090"
    healthcheck:
      test: "curl --fail --silent localhost:8090/actuator/health | grep UP || exit 1"
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 10s

    environment:
      SPRING_APPLICATION_NAME: "loans"
    extends:
      file: common-config.yml
      service: microservice-eureka-config

  cards:
    image: "150478/cards:v6"
    container_name: cards-ms
    ports:
      - "9000:9000"
    healthcheck:
      test: "curl --fail --silent localhost:9000/actuator/health | grep UP || exit 1"
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 10s

    environment:
      SPRING_APPLICATION_NAME: "cards"
    extends:
      file: common-config.yml
      service: microservice-eureka-config

  gatewayserver:
    image: "150478/gatewayserver:v6"
    container_name: gatewayserver-ms
    ports:
      - "8072:8072"
    depends_on:
      accounts:
        condition: service_healthy
      loans:
        condition: service_healthy
      cards:
        condition: service_healthy


    environment:
      SPRING_APPLICATION_NAME: "gatewayserver"

    extends:
      file: common-config.yml
      service: microservice-eureka-config

networks:
  zettabank:
    driver: "bridge"



default cmd> docker compose up -d


POSTMAN  GET   gatewayserver  accounts/api/fetchCustomerDetails

create accounts, cards , loans ad then fetchCustomerDetails

in browser open grafana dashboard - http://localhost:3000

menu > Connections	 Data sources > Loki  --- Explore
   -- do operations
   Select label : container
   Select value : accounts-ms or any other		> Run Query

   filter correlation-id




cmd> docker compose down



----------- Managing Metrics & monitoring with Spring Boot Actuator, Micrometer, Prometheus & Grafana --------------

first pillar for observability and monitoring is Logging
second pillar is Metrics
we cannot monitor our application only with logs. with the help of event logs we can only try to understand what happend under a specific scenario or under a specific method. with the help of only logs we cannot understand the overall health of our microservices.

to properly monitor our microservices we need to understand metrics related details like CPU usage, memory usage, threads usage/ heap dump usage, connections, errors etc. there are many matrics are available to properly monitor our applications 

135

/actuator/metrics - under this metrics actuator path there will be many metrics that can help you to monitor your microservice instance, it is not feasible to move through all service's actuator to understand the overall health of our application

Prometheus - opensource component to extract and aggregate all the metrics from the microservice  instances running inside our microservice network
	- prometheus cannot understand the metrics provided by actuator which exposes the metrics information in JSON format ; so that we need to use micrometer

micrometer - automatically exposes /actuator/metrics data into something your monitoring system can understand 

-- micrometer.io
facade design pattern -> going to deploy a front facing interface that will handle lot of complexity behind the scenes - it is going to support prometheus

prometheus - collects all the metrics from the respective microservice's containers and develop the dashboard and graphs

-- prometheus.io 

integrate prometheus with grafana

----------- Setup of micrometer inside Microservices --------------

accounts and in all microservices  - pom.xml 

dependency - Prometheus (micrometer-registry-prometheus -to expose the actuator metrics in a format our promotheus can understand)

application.yml of accounts, loans, cards, configserver, eureka, gatewayserver --

 management.metrics.tags.application: ${spring.application.name}   ---> to tell the micrometer and prometheus please group all the metrics related to the "accounts" microservice under the application name "accounts"; which helps to identity the metrics of each microservice

run - configserver, eureka server, accounts, loans, cards, gatewayserver

-- to see how the micrometer is exposing the details
browser http://localhost:8080/actuator
	http://localhost:8080/actuator/metrics
	http://localhost:8080/actuator/metrics/system.cpu.usage
	http://localhost:8080/actuator/metrics/process.uptime

	http://localhost:8080/actuator/prometheus	--> shows all the metrics information which are present in a format which our prometheus can understand ; prometheus is going to invoke this API path for every 5 seconds or 10 seconds or every 15 seconds based on configuration inside prometheus

	http://localhost:8090/actuator/prometheus
	http://localhost:9000/actuator/prometheus
	http://localhost:8070/actuator/prometheus
	http://localhost:8071/actuator/prometheus


----------- Setup of prometheus inside Microservices --------------

docker-compose/observability/prometheus/prometheus.yml

global:
  scrape_interval:     5s # Set the scrape interval to every 5 seconds.
  evaluation_interval: 5s # Evaluate rules every 5 seconds.

scrape_configs:
  - job_name: 'accounts'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: [ 'accounts:8080' ]
  - job_name: 'loans'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: [ 'loans:8090' ]
  - job_name: 'cards'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: [ 'cards:9000' ]
  - job_name: 'gatewayserver'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: [ 'gatewayserver:8072' ]
  - job_name: 'eurekaserver'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: [ 'eurekaserver:8070' ]
  - job_name: 'configserver'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: [ 'configserver:8071' ]
  

--docker-compose.yml ---

services:
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ../observability/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    extends:
      file: common-config.yml
      service: network-deploy-service
				

docker-compose/observability/grafana/datasource.yml

apiVersion: 1

deleteDatasources:
  - name: Prometheus
  - name: Loki
  - name: Tempo

datasources:
  - name: Prometheus
    type: prometheus
    uid: prometheus
    url: http://prometheus:9090
    access: proxy
    orgId: 1
    basicAuth: false
    isDefault: false
    version: 1
    editable: true
    jsonData:
      httpMethod: GET

  - name: Loki
    type: loki
    uid: loki
    access: proxy
    orgId: 1
    editable: true
    url: http://gateway:3100
    jsonData:
      httpHeaderName1: "X-Scope-OrgID"
      derivedFields:
        - datasourceUid: tempo
          matcherRegex: "\\[.+,(.+),.+\\]"
          name: TraceID
          url: '$${__value.raw}'
    secureJsonData:
      httpHeaderValue1: "tenant1"


inside docker-compose.yml - for grafana service
   volumes:
      - ../observability/grafana/datasource.yml:/etc/grafana/provisioning/datasources/datasource.yml


regenerate docker images

cmd>docker compose up -d

http://localhost:8080/actuator/prometheus

http://localhost:9090/targets    ---- 9090 - prometheus port

	Graph     search : cpu_usage / system_cpu_usage
		  search : process_up_time / threads / connection

-- to check unhealthy metrics --
kill card-ms from docker desktop
  check-in prometheus dashboard

start cards-ms
  check-in prometheus dashboard

--prometheus is continuouly monitoring the overall health of services -----

--> we are able to access only limited data using prometheus to overcome that

----------- Prometheus & Grafana Integration --------------

http://localhost:3000
	--- connections > Datasources -- Prometheus

	menu > Explore
    		Prometheus
Metric: system_cpu_usage
Label Filters: application	Run Query